function spark3(sparkMaster)
    % spark3 Small Spark example using RelationalGroupedDataset
    
    % Copyright, MathWorks 2020
    
    if nargin < 1
        sparkMaster = 'local';
    end
    
    appName = [mfilename, '-', datestr(now,30)];
    
    import matlab.compiler.mlspark.*
    
    spark = getDefaultSparkSession(appName, sparkMaster);
    
    % First, we read some raw data from a CSV file.
    outagesCSV = which('outages.csv');
    tic;
    outages = spark.read.format("csv") ...
        .option("header", "true") ...
        .option("inferSchema", "true") ...
        .load(addFileProtocol(outagesCSV));
    csvRead = toc %#ok<NASGU,NOPRT>
    
    gbds = outages.groupBy(...
        functions.year(outages.col('OutageTime')), ...
        functions.month(outages.col('OutageTime')) ...
        );
    
    dsAgg = gbds.agg(functions.round( ...
        functions.sum(outages.col("Customers")), ... The sum of the column
        2 ... Round to 2 decimals
        ));
    
    dsAgg.show(5)
    
    ODS = outages ...
        .withColumn("OutageDate", functions.to_date(outages.col("OutageTime"))) ...
        .withColumn("DatePlus5Days", functions.date_add(outages.col("OutageTime"), 5)) ...
        .withColumn("DateMinus10Days", functions.date_sub(outages.col("OutageTime"), 10)) ...
        .withColumn("DatePlus2Months", functions.add_months(outages.col("OutageTime"), 2)) ...
        .withColumn("DateMinus3Months", functions.add_months(outages.col("OutageTime"), -3)) ...
        ;
    ODS.show(5)
    
    dODS = ODS.filter(ODS.col("OutageDate").between("2003-01-01", "2003-12-31"));
    cODS = ODS.filter(ODS.col("Customers").between(50e3, 80e3));
    fprintf([ ...
        'Outage entries:                                    %d\n', ...
        'Outage entries in 2003:                            %d\n', ...
        'Outage entries with between 50k and 80k customers: %d\n'], ...
        ODS.count, dODS.count, cODS.count);
    
    fprintf('### Finished example %s\n', mfilename);
end
